# Transfer Learning with Feature Extractor (classification)
- [Feature extraction](https://en.wikipedia.org/wiki/Feature_extraction)
- [Transfer learning](https://en.wikipedia.org/wiki/Transfer_learning)
- [Teachable Machine](https://teachablemachine.withgoogle.com/)


---

- `index.html`

```html
<!DOCTYPE html>
<html>
  <head>
    <title>ml5.js 연습</title>
    <meta charset="utf-8">
    <script src="https://cdn.jsdelivr.net/npm/p5@1/lib/p5.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/p5@1/lib/addons/p5.sound.min.js"></script>
    <script src="https://unpkg.com/ml5@latest/dist/ml5.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/IDMNYU/p5.js-speech@0.0.3/lib/p5.speech.js"></script>
  </head>

  <body>
    <h1>Feature Extractor (classification)</h1>
    <script src="sketch.js"></script>
  </body>
</html>
```

---

- `sketch.js` (0) - custom image classification
  - [ ] 배경이 단일색으로 가능한 한 단순해야 할 것
  - [ ] 사람의 신체 부위가 지나치게 개입된 상태로 이미지 추가 하지 말 것
  - [ ] 개입된 사람의 신체에 비하여 상대적으로 작은 물체는 판별하기 어려움


```javascript
let mobilenet;  // pre-trained model
let classifier; // user's model
let video;
let label = 'test';
let button1;  // object 1
let button2;  // object 2
let button3;  // train

function setup() {
  createCanvas(640, 550);
  video = createCapture(VIDEO);
  video.hide();
  mobilenet = ml5.featureExtractor('MobileNet', modelReady);
  classifier = mobilenet.classification(video, videoReady);
  
  button1 = createButton('object 1');
  button2 = createButton('object 2');
  button3 = createButton('train');
  
  button1.mousePressed(addImage1);
  button2.mousePressed(addImage2);
  button3.mousePressed(trainImage);
}

function modelReady() {
  console.log('Model is ready!');
}

function videoReady() {
  console.log('Video is ready!');
}

function addImage1() {
  console.log('Object 1 is added!');
  classifier.addImage('object 1');
}

function addImage2() {
  console.log('Object 2 is added!');
  classifier.addImage('object 2');
}

function trainImage() {
  console.log('Image training starts!');
  classifier.train(whileTraining);
}

function whileTraining(loss) {
  // 오차함수 (error function, loss function, cost function)
  if (loss == null) {
    console.log('Training finished!');
    classifier.classify(gotResults);
  } else {
    console.log(loss);  
  }
}

function gotResults(error, results) { 
  if (error) {
      console.log(error);
  } else {
      label = results[0].label;
      classifier.classify(gotResults);
  }
}

function draw() {
  background(0);
  image(video, 0, 0);
  fill(0, 255, 255);
  textSize(32);
  text(label, 10, height - 20);
}
```

---

- [ ] 실습: 행복한(happy) 표정과 슬픈(sad) 표정을 학습시키고 인공지능이 나의 감정 상태를 구별하도록 해보자. (과장된 표정일수록 좋은 성능)


---

- `sketch.js` (1) Save/Load custom model
  - [ ] `model.json`(메타화일)과 `model.weights.bin`(이진화일) 디폴트 다운로드 디렉토리로 다운로드
  - [ ] 이진화일은 VSCode 확장팩 `Hex Edit` 설치 후 열어볼것
  - [ ] Linux `mv` 명령어 사용하여 현재 작업 디렉토리로 이동시 기존의 같은 이름의 화일들은 덮어쓰기 되므로 주의할 것 
  - [ ] 존재하지 않는 화일들은 load 할 수 없음 


  ```sh
  pwd  # 현재 작업 디렉토리 체크 (present working directiory) (이후 명령어에서 간단히 . 을 대신 사용함)
  mv 디폴트 다운로드 디렉토리/model.json .
  mv 디폴트 다운로드 디렉토리/model.weights.bin .
  ```

```javascript
let mobilenet;  // pre-trained model
let classifier; // user's model
let video;
let label = '';
let button1;  // object 1
let button2;  // object 2
let button3;  // train
let button4;  // save
let button5;  // load


function setup() {
  createCanvas(640, 550);
  video = createCapture(VIDEO);
  video.hide();
  mobilenet = ml5.featureExtractor('MobileNet', modelReady);
  classifier = mobilenet.classification(video, videoReady);
  
  button1 = createButton('object 1');
  button2 = createButton('object 2');
  button3 = createButton('train');
  button4 = createButton('save');
  button5 = createButton('load');
  
  button1.mousePressed(addImage1);
  button2.mousePressed(addImage2);
  button3.mousePressed(trainImage);
  button4.mousePressed(saveMyModel);
  button5.mousePressed(loadMyModel);
}

function modelReady() {
  console.log('Model is ready!');
}

function videoReady() {
  console.log('Video is ready!');
}

function addImage1() {
  console.log('Object 1 is added!');
  classifier.addImage('object 1');
}

function addImage2() {
  console.log('Object 2 is added!');
  classifier.addImage('object 2');
}

function trainImage() {
  console.log('Image training starts!');
  classifier.train(whileTraining);
}

function saveMyModel() {
  console.log('Custom model is saved!');
  classifier.save();
}

function loadMyModel() {
  // 주의: loadModel 을 함수명으로 사용하지 말것 (ml5와 충돌)
  console.log('Load custom model!');
  classifier.load('model.json', customModelReady);  // 메뉴얼 참조
}

function whileTraining(loss) {
  // 오차함수 (error function, loss function, cost function)
  if (loss == null) {
    console.log('Training finished!');
    classifier.classify(gotResults);
  } else {
    console.log(loss);  
  }
}

function customModelReady() {
  console.log('Custom Model is ready!!!');
  label = 'Custom model is ready';
  classifier.classify(gotResults);
}

function gotResults(error, results) { 
  if (error) {
      console.log(error);
  } else {
      label = results[0].label;
      classifier.classify(gotResults);
  }
}

function draw() {
  background(0);
  image(video, 0, 0);
  fill(0, 255, 255);
  textSize(32);
  text(label, 10, height - 20);
}
```
