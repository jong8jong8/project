# Handpose for palm detection and hand-skeleton finger tracking 
- [TensorFlow.js Handpose implementation](https://github.com/tensorflow/tfjs-models/tree/master/hand-pose-detection)


![](https://camo.githubusercontent.com/b0f077393b25552492ef5dd7cd9fd13f386e8bb480fa4ed94ce42ede812066a1/68747470733a2f2f6d65646961706970652e6465762f696d616765732f6d6f62696c652f68616e645f6c616e646d61726b732e706e67)
---

- `index.html` 

```html
<!DOCTYPE html>
<html>
  <head>
    <title>ml5.js 연습</title>
    <meta charset="utf-8">
    <script src="https://cdn.jsdelivr.net/npm/p5@1/lib/p5.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/p5@1/lib/addons/p5.sound.min.js"></script>
    <script src="https://unpkg.com/ml5@latest/dist/ml5.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/IDMNYU/p5.js-speech@0.0.3/lib/p5.speech.js"></script>
  </head>

  <body>
    <h1>Handpose for palm detection and hand-skeleton finger tracking</h1>
    <script src="sketch.js"></script>
  </body>
</html>
```


---

- `sketch.js` (0) - 

```javascript
let video;
let handpose;

function setup() {
  createCanvas(640, 480);
  video = createCapture(VIDEO);
  video.hide();
  handpose = ml5.handpose(video, modelLoaded);
  handpose.on('hand', gotPoses);
}

function modelLoaded() {
  console.log('Handpose is ready');
}

function gotPoses(poses){
  console.log(poses);
}

function draw() {
  push();
  // flip image's left and right
  translate(video.width, 0);
  scale(-1, 1);
  image(video, 0, 0);

  pop();
}
```
